```{r}

################
# Load packages
################

# Required packages
if (!require(pacman))
  install.packages("pacman")

pacman::p_load(dplyr,
               Hmisc,
               tidyr,
               imputeTS,
               impute,
               lubridate,
               tidymodels,
               tidyverse,
               ranger,
               randomForest,
               glmnet,
               here,
               formattable,
               dlookr,
               yardstick,
               gridExtra,
               VIM,
               DMwR2)
```

```{r}

{r}
#| label: dallas-dataset 
#| echo: false
#| warning: false

# Load Dallas data

dallas_data <- read_csv(here('./data/dallas21.csv'))

# List of columns we will analyze:

columns_to_extract <- c("DATE",
"NAME",
"HourlyAverageDryBulbTemperature",
"HourlyAverageWetBulbTemperature",
"HourlyAverageDewPointTemperature",
"HourlyPrecipitation",
"HourlyAverageSeaLevelPressure",
"HourlyAverageStationPressure",
"HourlyAverageRelativeHumidity",
"HourlyAverageWindSpeed",
"HourlySustainedWindDirection")

cleaned_dallas <- dallas_data[, columns_to_extract]

# Dimensions of dataset: 
num_rows <- nrow(cleaned_dallas)
num_columns <- ncol(cleaned_dallas)
cat("(", num_rows, " rows x ", num_columns, " columns)", sep = "")

cleaned_dallas |>
  head(n = 5) |>
  formattable()
```

```{r}

############
# Load data
############

original_data <- read_csv(here('./data/arlington-2022.csv'))
original_data
#shortened_data <- head(original_data, 100)
#shortened_data |> formattable()

# Creating a "SunLogisticValues" column
# (The below no longer matters)
#shortened_data <- shortened_data %>%
#  mutate(SunLogisticValues = !is.na(Sunset))
#shortened_data

write.csv(shortened_data, "C:/Users/kendallbeaver/Downloads/just_column_data.csv", row.names = FALSE)
```

```{r}
# Convert Riyanishi's Python code into R code to categorize day and night

categorize_day_night <- function(hour) {
  if (hour >= 6 && hour < 18) {
    return('Daytime')
  } else {
    return('Nighttime')
  }
}

# Apply the function to your datasets
original_data$Day_Night <- sapply(original_data$Hour, categorize_day_night)
#dallas$Day_Night <- sapply(dallas$Hour, categorize_day_night)
#denton$Day_Night <- sapply(denton$Hour, categorize_day_night)
```

```{r}

##################################################
# Separate sunset & sunrise into distinct datasets
##################################################

# The below is already in POSIX format
# original_data$DATE <- as.POSIXct(original_data$DATE, format = "%Y-%m-%d %H:%M:%S")

# Extract time from the DATE column (which has DATE & TIME smashed together in one cell)
original_data$DateOnly <- format(original_data$DATE, "%H:%M")
#original_data$SunriseFormatted <- as.POSIXct(original_data$Sunrise, format = "%H:%M")

original_data$SunriseFormatted <- ifelse(!is.na(original_data$Sunrise) & is.numeric(original_data$Sunrise), format(strptime(as.numeric(original_data$Sunrise), format = "%H%M"), "%H:%M"), NA)
original_data$SunriseFormatted

#original_data$SunriseFormatted <- format(strptime(as.numeric(original_data$Sunrise), format = "%H%M"), "%H:%M")


original_data$SunriseFormatted

write.csv(original_data, "C:/Users/kendallbeaver/Downloads/mutated_data.csv", row.names = FALSE)
```

```{r}
#####################
# Show missing values
#####################

missing_values <- original_data %>% 
  summarise_all(list(~ sum(is.na(.))))

#missing_values <- original_data %>% summarize_all(funs(sum(is.na(.))))

#original_data <- any(is.na(original_data))
#original_data[original_data == ""] <- NA

missing_values
```

```{r}
############
# Clean data
############

# First, remove the "REM" column

original_data <- original_data %>% select(-DATE)

# The asterick needs to be imputed as a missing value

original_data[original_data == "*"] <- NA

# Convert "T" to "NA", then "VRB" to "NA"
original_data$HourlyPrecipitation <- ifelse(original_data$HourlyPrecipitation == "T", NA, original_data$HourlyPrecipitation)

original_data$HourlyPrecipitation <- ifelse(original_data$HourlyPrecipitation == "VRB", NA, original_data$HourlyPrecipitation)

# Remove "-s" from end of data

original_data <- mutate_all(original_data, ~sub("s$", "", .))

#original_data$HourlyPrecipitation <- sub("s$", "", original_data$HourlyPrecipitation)

original_data
```

```{r}

# Missing values

missing_values <- original_data %>% 
  summarise_all(list(~ sum(is.na(.))))

descending_list_of_missing_values <- original_data %>% 
  summarise_all(list(~ sum(is.na(.)))) %>% 
  gather(key = "column", value = "missing_count") %>%
  arrange(desc(missing_count))

descending_list_of_missing_values

write.csv(original_data, "C:/Users/kendallbeaver/Downloads/imputed_data.csv", row.names = FALSE)

imputed_data <- knnImputation(original_data, k = 50, meth="median")
imputed_data
```

\

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAaCAYAAACpSkzOAAABAklEQVR42mNgGAVDCqxdvzVhzcbNm6mBK6uqVuO06P///4xr128pptSSmtrarSCz8Ppq//79LGs3bGkl15K6hsZ9IDOICsJFO3dyr1m/tZdUS+obGw+D9JIUX6tW7eZfs2HLLGItaWxqPQXSQ17iWLtDEhiMSwhZ0tzceh6klqKUuGrjdvU1G7esxGVJU0vbJZAaqiT7NRs36q3ZsHU9hiWtbVdBclTNY6vXb3YAWrYJHlyt7ddAYrTJ0Bs2h0B80n4dxB4t4lAA4yK/zdTAhC1a4LOZYZsnRRhsBkGLZntRbhHIDIIWTfek3CKQGQQtmuxGuUUgMwiCPpfNVMGjYMgBAEpfBd1AknheAAAAAElFTkSuQmCC "Run All Chunks Above")![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAaCAYAAADFTB7LAAAAa0lEQVR42u3OywnAIBBAwcXSUoCW5D11xDoNCBGNv0MOecJOBSOi1OZMsJ4dvFxEJ1OQnMxBarIKEpNNkJbsBknJYZCSnAYJyVVQziNig7/nZkFEbhTE5HpBVO4dxOXKIDL3BLG5BJ1T6rsbMfep2CaMN00AAAAASUVORK5CYII= "Run Current Chunk")

```{r}
# Extract "Daily" columns

columns_to_extract <- c("HourlyDryBulbTemperature",
                        "HourlyWetBulbTemperature",
                        "HourlyDewPointTemperature",
                        "HourlyStationPressure",
                        "HourlyRelativeHumidity",
                        "HourlyWindSpeed")

daily_data_arlington <- original_data[, columns_to_extract]

daily_data_arlington <- mutate_all(daily_data_arlington, function(x) ifelse(x < 0, 0, x))

char_columns <- sapply(daily_data_arlington, is.character)

daily_data_arlington[, char_columns] <- lapply(daily_data_arlington[, char_columns], as.numeric)
#daily_data_arlington |> summary()

daily_data_arlington <- mutate_all(daily_data_arlington, ~sub("s$", "", .))
#daily_data_arlington

daily_data_arlington[is.na(daily_data_arlington)] <- NA

#daily_data_arlington <- impute(daily_data_arlington)
#daily_data_arlington <- as.numeric(daily_data_arlington)

#max_decimal <- max(nchar(sub(".*\\.", "", as.character(daily_data_arlington))))
#formatted_data <- sprintf(paste0("%.", max_decimal, "f"), daily_data_arlington)
#daily_data_arlington <- head(formatted_data, 362)

#daily_data_arlington <- head(daily_data_arlington, 361)
#daily_data_arlington

###################
# ROWS TO REMOVE!!!
###################
rows_to_remove <- c(361, 362, 364, 5008, 5214, 5215, 5216, 5221, 5222, 5876, 6499, 6705, 6715, 8077, 8078, 8079)
# There's some type of glitch where it thinks 5231 & 5232 are "5221 & 5222"

daily_data_arlington <- daily_data_arlington[-rows_to_remove, ]
daily_data_arlington
```

```{r}
###################################################
# Imputing subset to isolate "knnImputation" issues
###################################################

subset_1_arlington_data <- daily_data_arlington[0:5000, ]
subset_1_arlington_data
imputed_data <- knnImputation(subset_1_arlington_data, k = 10, meth="median")
imputed_data

subset_2_arlington_data <- daily_data_arlington[8700:10000, ]
subset_2_arlington_data
imputed_data <- knnImputation(subset_2_arlington_data, k = 10, meth="median")
imputed_data

#daily_data_arlington <- data.matrix(daily_data_arlington)
#imputed_data <- knnImputation(daily_data_arlington, k = 10, meth="median")
#imputed_data

# Subset the first 362 rows of the dataset
#subset_data <- head(daily_data_arlington, 362)
#any(is.na(subset_data))
#imputed_data <- knnImputation(subset_data, k = 10, meth = "median")


#write.csv(daily_data_arlington, "C:/Users/kendallbeaver/Downloads/imputed_data.csv", row.names = FALSE)
```

```{r}

# Impute Arlington dataset

imputed_data <- knnImputation(daily_data_arlington, k = 20, meth="median")
imputed_data

# Riyanshi fixed this in Python
```

Extra code/ideas 12/5/23:

```{r}
plt.figure(figsize=(10, 6))
sns.boxplot(x="UHI Intensity", y="DailyAverageDryBulbTemperature", data=dallas, order=["Low", "Medium", "High"])

# Set plot labels and title
plt.xlabel("UHI Intensity")
plt.ylabel("Daily Average Dry Bulb Temperature")
plt.title("Daily Avg Dry Bulb Temperature by UHI Intensity")

# Show the plot
plt.show()
```

```{Python}

# UHI Intensity Seasonal Nightly Avg Temp - Dallas

# First format data
dallas['HourlyDryBulbTemperature'] = pd.to_numeric(dallas['HourlyDryBulbTemperature'], errors='coerce')
dallas['Date'] = pd.to_datetime(dallas['Date'])

# Filter rows only for 'Nighttime'
nighttime_data = dallas[dallas['Day_Night'] == 'Nighttime']

# Calculate the mean for each date
average_night_temp_dallas = nighttime_data.groupby('Date')['HourlyDryBulbTemperature'].mean()

# Merge average back to the original DataFrame based on the 'Date'
dallas = dallas.merge(average_night_temp_dallas.reset_index(name='average_night_temp_dallas'), on=['Date'], how='left')

# Adding grid style to the plot
sns.set(style="whitegrid")

# Creating boxplot with different colors for "Season"
plt.figure(figsize=(12, 8))
sns.boxplot(x="UHI Intensity", y="average_night_temp_dallas", hue="Season", data=dallas,
            order=["Low", "Medium", "High"], hue_order=["Winter", "Spring", "Summer", "Fall"])

# Set plot labels and title
plt.xlabel("UHI Intensity")
plt.ylabel("Nightly Avgerate Temperature")
plt.title("Seasonal Nightly Avg Temp by UHI Intensity - Dallas")

# Show the legend
plt.legend(title="Season")

# Show the plot
plt.show()




# UHI Intensity Seasonal Nightly Avg Temp - Arlington

# First format data
arlington['HourlyDryBulbTemperature'] = pd.to_numeric(arlington['HourlyDryBulbTemperature'], errors='coerce')
arlington['Date'] = pd.to_datetime(arlington['Date'])

# Filter rows only for 'Nighttime'
nighttime_data = arlington[arlington['Day_Night'] == 'Nighttime']

# Calculate the mean for each date
average_night_temp_arlington = nighttime_data.groupby('Date')['HourlyDryBulbTemperature'].mean()

# Merge average back to the original DataFrame based on the 'Date'
arlington = arlington.merge(average_night_temp_arlington.reset_index(name='average_night_temp_arlington'), on=['Date'], how='left')

# Adding grid style to the plot
sns.set(style="whitegrid")

# Creating boxplot with different colors for "Season"
plt.figure(figsize=(12, 8))
sns.boxplot(x="UHI Intensity", y="average_night_temp_arlington", hue="Season", data=arlington,
            order=["Low", "Medium", "High"], hue_order=["Winter", "Spring", "Summer", "Fall"])

# Set plot labels and title
plt.xlabel("UHI Intensity")
plt.ylabel("Nightly Avgerate Temperature")
plt.title("Seasonal Nightly Avg Temp by UHI Intensity - Arlington")

# Show the legend
plt.legend(title="Season")

# Show the plot
plt.show()


# UHI Intensity Seasonal Nightly Avg Temp - Denton

# First format data
denton['HourlyDryBulbTemperature'] = pd.to_numeric(denton['HourlyDryBulbTemperature'], errors='coerce')
denton['Date'] = pd.to_datetime(denton['Date'])

# Filter rows only for 'Nighttime'
nighttime_data = denton[denton['Day_Night'] == 'Nighttime']

# Calculate the mean for each date
average_night_temp_denton = nighttime_data.groupby('Date')['HourlyDryBulbTemperature'].mean()

# Merge average back to the original DataFrame based on the 'Date'
denton = denton.merge(average_night_temp_denton.reset_index(name='average_night_temp_denton'), on=['Date'], how='left')

# Adding grid style to the plot
sns.set(style="whitegrid")

# Creating boxplot with different colors for "Season"
plt.figure(figsize=(12, 8))
sns.boxplot(x="UHI Intensity", y="average_night_temp_denton", hue="Season", data=denton,
            order=["Low", "Medium", "High"], hue_order=["Winter", "Spring", "Summer", "Fall"])

# Set plot labels and title
plt.xlabel("UHI Intensity")
plt.ylabel("Nightly Avgerate Temperature")
plt.title("Seasonal Nightly Avg Temp by UHI Intensity - Denton")

# Show the legend
plt.legend(title="Season")

# Show the plot
plt.show()

```

Testing in Dhayna's code on 12/9/23 (7:12 pm):

```{python}

# Kendall - running test for daily average values:

import pandas as pd

# Read the data
new_dallas = pd.read_csv('https://raw.githubusercontent.com/INFO-523-Exercises/project-final-Byte-Busters/main/data/Dallas.csv', header='infer' ,low_memory=False)
new_arlington = pd.read_csv('https://raw.githubusercontent.com/INFO-523-Exercises/project-final-Byte-Busters/main/data/Arlington.csv', header='infer' ,low_memory=False)
new_denton = pd.read_csv('https://raw.githubusercontent.com/INFO-523-Exercises/project-final-Byte-Busters/main/data/Denton.csv', header='infer' ,low_memory=False)

# Convert 'DATE' column to datetime format
new_denton['DATE'] = pd.to_datetime(new_denton['DATE'])
new_dallas['DATE'] = pd.to_datetime(new_dallas['DATE'])
new_arlington['DATE'] = pd.to_datetime(new_arlington['DATE'])

def get_season(month):
    if month in [12, 1, 2]:
        return 'Winter'
    elif month in [3, 4, 5]:
        return 'Spring'
    elif month in [6, 7, 8]:
        return 'Summer'
    elif month in [9, 10, 11]:
        return 'Fall'
    else:
        return None

# Apply the function to create a new 'Season' column
new_denton['Season'] = new_denton['DATE'].dt.month.apply(get_season)
new_dallas['Season'] = new_dallas['DATE'].dt.month.apply(get_season)
new_arlington['Season'] = new_arlington['DATE'].dt.month.apply(get_season)

columns_of_interest = ['DATE','DailyAverageDryBulbTemperature', 'DailyAverageWetBulbTemperature', 'DailyAverageDewPointTemperature',
                       'DailyPrecipitation', 'DailyAverageSeaLevelPressure', 'DailyAverageStationPressure',
                       'DailyAverageRelativeHumidity', 'DailyAverageWindSpeed', 'DailyPeakWindDirection', 'Season']

# Select only the columns of interest from each dataset
new_denton = new_denton[columns_of_interest]
new_dallas = new_dallas[columns_of_interest]
new_arlington = new_arlington[columns_of_interest]

# Recheck for missing values
#print("Remaining Missing Values in Denton Dataset:\n", new_denton.isnull().sum())
#print("\nRemaining Missing Values in Dallas Dataset:\n", new_dallas.isnull().sum())
#print("\nRemaining Missing Values in Arlington Dataset:\n", new_arlington.isnull().sum())

# Add a new column 'City' to each dataset
new_denton['City'] = 'Denton'
new_dallas['City'] = 'Dallas'
new_arlington['City'] = 'Arlington'

# Check if all datasets have the same columns and column order
print(new_denton.columns == new_dallas.columns)
print(new_denton.columns == new_arlington.columns)

# Concatenate the datasets
combined_data_new = pd.concat([new_denton, new_dallas, new_arlington])

# Filter the combined data for rows where the 'Season' is 'Summer'
combined_data_new = combined_data_new[(combined_data_new['Season'] == 'Summer')]

def categorize_uhi_intensity(row):
    # Initialize the score
    score = 0

    # Check for combinations of conditions rather than individual thresholds
    # For instance, high temperature with high humidity (%)
    if row['DailyAverageDryBulbTemperature'] > 85 and row['DailyAverageRelativeHumidity'] > 70:
        score += 2
    elif row['DailyAverageDryBulbTemperature'] > 70 and row['DailyAverageRelativeHumidity'] > 60:
        score += 1

    # Consider wind speed and temperature together
    if row['DailyAverageWindSpeed'] < 5 and row['DailyAverageDryBulbTemperature'] > 80:
        score += 1

    # Use Heat Index with a higher threshold to make it more challenging
#    if row['HeatIndex'] > 105:
#        score += 1

    # Use Wind Chill in combination with Day-Night Temperature Difference
#    if row['WindChillTemperature'] < 50 and row['DayNightTempDiff'] > 15:
#        score += 1

    # Interpret the score for UHI intensity
    if score >= 3: return 'High'
    elif score >= 1: return 'Medium'
    else: return 'Low'

# Apply the function to create the 'UHI_Intensity' column
combined_data_new['UHI_Intensity'] = combined_data_new.apply(categorize_uhi_intensity, axis=1)

# Count the occurrences of each category in the 'UHI_Intensity' column
uhi_intensity_counts = combined_data_new['UHI_Intensity'].value_counts()

# Display the counts
print(uhi_intensity_counts)
```
